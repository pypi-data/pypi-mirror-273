Metadata-Version: 2.1
Name: osc-llm
Version: 0.1.4
Summary: 大模型训练,评估,推理,部署工具
License: MIT
Author: wangmengdi
Author-email: 790990241@qq.com
Requires-Python: >=3.8
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Requires-Dist: catalogue (>=2.0.10)
Requires-Dist: confection (>=0.1.4)
Requires-Dist: fastapi (>=0.110.2)
Requires-Dist: jsonargparse (>=4.28.0)
Requires-Dist: lightning (>=2.2.0)
Requires-Dist: pydantic (>=1.10.8)
Requires-Dist: sentencepiece (>=0.2.0)
Requires-Dist: tokenizers (>=0.19.1)
Requires-Dist: torch (>=2.3.0)
Requires-Dist: uvicorn[standard] (>=0.29.0)
Requires-Dist: wasabi (>=1.1.2)
Description-Content-Type: text/markdown

<div align='center'>

# OSC-LLM
<a href="https://pytorch.org/get-started/locally/"><img alt="PyTorch" src="https://img.shields.io/badge/PyTorch-ee4c2c?logo=pytorch&logoColor=white"></a>
<a href="https://lightning.ai/docs/overview/getting-started"><img alt="Lightning" src="https://img.shields.io/badge/-Lightning-792ee5?logo=pytorchlightning&logoColor=white"></a>

</div>

## 📌&nbsp;&nbsp; 简介

## 📌&nbsp;&nbsp; 安装

- 安装[最新版本pytorch](https://pytorch.org/get-started/locally/)
- 安装osc-llm: `pip install osc-llm`

## 📌&nbsp;&nbsp; 快速开始
```bash
# 下面以llama3为例演示如何转换为osc-llm格式,并进行聊天。
# 假设你已经下载好huggingface的llama3模型在checkpoints/meta-llama目录下
# 1. 转换模型
llm convert --checkpoint_dir checkpoints/meta-llama/Meta-Llama-3-8B-Instruct
# 2. 量化模型
llm quantize int8 --checkpoint_dir checkpoints/meta-llama/Meta-Llama-3-8B-Instruct --save_dir checkpoints/meta-llama/Meta-Llama-3-8B-Instruct-int8
# 3. 聊天(使用编译功能加速推理速度,需要等待几分钟编译时间)
llm chat --checkpoint_dir checkpoints/meta-llama/Meta-Llama-3-8B-Instruct-int8 --compile true
# 4. 部署简易版本openai服务
llm serve --checkpoint_dir checkpoints/meta-llama/Meta-Llama-3-8B-Instruct-int8
```

## 📌&nbsp;&nbsp; 模型支持

以下huggingface中的模型结构(查看config.json)已经支持转换为osc-llm格式:
- **LlamaForCausalLM**: llama2, llama3, chinese-alpaca2等。
- **Qwen2ForCausalLM**: qwen1.5系列。
- **Qwen2MoeForCausalLM**: qwen2-moe系列(目前无法完成编译,推理速度很慢)。


### 致敬
本项目参考了大量的开源项目，特别是以下项目：

- [litgpt](https://github.com/Lightning-AI/litgpt)
- [gpt-fast](https://github.com/pytorch-labs/gpt-fast)
