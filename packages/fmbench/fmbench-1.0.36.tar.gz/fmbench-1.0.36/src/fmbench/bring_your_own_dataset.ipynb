{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d144a1ec-e66d-45b8-baf1-af4641ee23ce",
   "metadata": {},
   "source": [
    "# Bring your own dataset\n",
    "\n",
    "---------\n",
    "*This notebook works best with the conda_python3 kernel on a ml.t3.medium machine*.\n",
    "\n",
    "### This part of our solution design includes \n",
    "\n",
    "- Creating your own `fmbench` compatible dataset from a [HuggingFace dataset](https://huggingface.co/docs/datasets/en/index).\n",
    "\n",
    "- Creating a prompt payload template compatible with your dataset.\n",
    "\n",
    "- Upload the dataset and the prompt payload to Amazon S3 from where it can be used by `fmbench`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafa135b-2dec-4e2c-9821-bd8268a21492",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if interactive mode is set to no -> pickup fmbench from Python installation path\n",
    "# if interactive mode is set to yes -> pickup fmbench from the current path (one level above this notebook)\n",
    "# if interactive mode is not defined -> pickup fmbench from the current path (one level above this notebook)\n",
    "# the premise is that if run non-interactively then it can only be run through main.py which will set interactive mode to no\n",
    "import os\n",
    "import sys\n",
    "if os.environ.get(\"INTERACTIVE_MODE_SET\", \"yes\") == \"yes\":\n",
    "    sys.path.append(os.path.dirname(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7343d0fb-89cc-48da-8c77-22b8024a7e94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fmbench.utils import *\n",
    "from fmbench.globals import *\n",
    "from datasets import load_dataset\n",
    "config = load_config(CONFIG_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89998f93-e59a-4d47-9957-ad0b11a089f7",
   "metadata": {},
   "source": [
    "## Convert HuggingFace dataset to jsonl format\n",
    "\n",
    "`fmbench` works with datasets in the [`JSON Lines`](https://jsonlines.org/) format. So here we show how to convert a HuggingFace dataset into JSON lines format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815d021d-ff1c-4275-85ae-128265b0d5fa",
   "metadata": {},
   "source": [
    "Set the `ds_name` to the HuggingFace dataset id, for example [`THUDM/LongBench`](https://huggingface.co/datasets/THUDM/LongBench), [`rajpurkar/squad_v2`](https://huggingface.co/datasets/rajpurkar/squad_v2), [`banking77`](https://huggingface.co/datasets/banking77) or other text datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657bad51-f5dd-45e0-a08c-cbfd33206301",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_id: str = \"rajpurkar/squad\"\n",
    "ds_name: str = \"plain_text\"\n",
    "ds_split: str = \"train\"\n",
    "# Take a random subset of the dataframe, adjust the value of `N` below as appropriate.\n",
    "# size of random subset of the data\n",
    "ds_N: int = 100\n",
    "\n",
    "# another example\n",
    "# ds_id: str = \"THUDM/LongBench\"\n",
    "# ds_name: str = \"2wikimqa\"\n",
    "# ds_split: str = \"test\"\n",
    "# Take a random subset of the dataframe, adjust the value of `N` below as appropriate.\n",
    "# size of random subset of the data\n",
    "# ds_N: int = 200\n",
    "\n",
    "# another example\n",
    "# ds_id: str = \"banking77\"\n",
    "# ds_name: str = \"default\"\n",
    "# ds_split: str = \"train\"\n",
    "# Take a random subset of the dataframe, adjust the value of `N` below as appropriate.\n",
    "# size of random subset of the data\n",
    "# ds_N: int = 10000\n",
    "\n",
    "ds_id: str = \"Open-Orca/OpenOrca\"\n",
    "ds_name: str = \"default\"\n",
    "ds_split: str = \"train\"\n",
    "# Take a random subset of the dataframe, adjust the value of `N` below as appropriate.\n",
    "# size of random subset of the data\n",
    "ds_N: int = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707c44bd-af91-4268-9d76-35544b0653e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the dataset from huggingface\n",
    "dataset = load_dataset(ds_id, name=ds_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e558518a-c24e-4f6d-becf-3fdbf6c10e78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c55120-b66a-4386-8371-d5544e3d54d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# convert the dataset to a dataframe, for print it out and easy conversion to jsonl\n",
    "df = pd.DataFrame(dataset[ds_split])\n",
    "\n",
    "# some datasets contain a field called column, we would like to call it\n",
    "# input to match it to the prompt template\n",
    "df.rename(columns={\"question\": \"input\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff18dd26-ad8f-449d-bcba-1dd96f00b6ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703cc0f9-a86b-42de-81b4-21a6a3048fe7",
   "metadata": {},
   "source": [
    "Subset the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c4e481-2cd4-4341-b910-c5172eafe400",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"dataset shape before random subset = {df.shape}\")\n",
    "df = df.sample(n=ds_N)\n",
    "print(f\"dataset shape before random subset = {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7fcadf-0ca7-4123-92d6-ed7b188cfd4b",
   "metadata": {},
   "source": [
    "Convert to json lines format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb38f44-9788-4d26-b77e-2dde3feddfb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jsonl_content = df.to_json(orient='records', lines=True)\n",
    "print(jsonl_content[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461c64b4-d0c8-41d5-80a2-86581d176a20",
   "metadata": {},
   "source": [
    "## Upload the dataset to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfecbb1-6355-4f52-86a4-53579d867629",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket: str = config['s3_read_data']['read_bucket']\n",
    "prefix: str = config['s3_read_data']['source_data_prefix']\n",
    "file_name: str = f\"{ds_id}.jsonl\"\n",
    "write_to_s3(jsonl_content, bucket, prefix, \"\", file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c6fd45-fc80-45f3-a184-9cad6a1cd706",
   "metadata": {},
   "source": [
    "## Create a prompt template and upload it to S3\n",
    "The prompt template is specific to the model under test and also the dataset being used. The variables used in the template, such as `context` and `input` must exist in the dataset being used so that this prompt template can be converted into an actual prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018df5ca-dd8a-4436-a1a6-c3204ac079d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dictionary containing the prompt template, it has a key by the name\n",
    "# of the dataset id which forces you to explicitly add your dataset here\n",
    "# otherwise no new prompt template will be uploaded and it wont accidently\n",
    "# end up overwriting an existing prompt template\n",
    "prompt_template = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef34360-c855-49e6-a624-0209ba09939f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LongBench\n",
    "prompt_template['THUDM-LongBench-llama2-mistral'] = \"\"\"<s>[INST] <<SYS>>\n",
    "You are an assistant for question-answering tasks. Use the following pieces of retrieved context in the section demarcated by \"```\" to answer the question. If you don't know the answer just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "<</SYS>>\n",
    "\n",
    "```\n",
    "{context}\n",
    "```\n",
    "\n",
    "Question: {input}\n",
    "\n",
    "[/INST]\n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac185446-2338-47ec-8c78-30dea736aaec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Open Orca\n",
    "prompt_template['Open-Orca-OpenOrca-llama2-mistral'] = \"\"\"<s>[INST] <<SYS>>\n",
    "\n",
    "{system_prompt}\n",
    "\n",
    "<</SYS>>\n",
    "\n",
    "Context and task: {input}\n",
    "\n",
    "[/INST]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d0009c-79b8-4cf9-8450-824a03ae5996",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_template['Open-Orca-OpenOrca-llama3'] = \"\"\"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "{system_prompt}\n",
    "\n",
    "Context and task: {input} \n",
    "\n",
    "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5771c28e-07c6-4805-b33d-186895496aed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# prompt template for BERT\n",
    "bucket: str = config['s3_read_data']['read_bucket']\n",
    "prefix: str = config['s3_read_data']['prompt_template_dir']\n",
    "for k in prompt_template.keys():\n",
    "    file_name: str = f\"prompt_template_{k}.txt\"\n",
    "    print(f\"writing {file_name} to s3://{bucket}/{prefix}/{file_name}\")\n",
    "    write_to_s3(prompt_template[k], bucket, prefix, \"\", file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024abdb8-7e42-4963-b572-18a05dc5e61d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_fmbench_python311",
   "language": "python",
   "name": "conda_fmbench_python311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
