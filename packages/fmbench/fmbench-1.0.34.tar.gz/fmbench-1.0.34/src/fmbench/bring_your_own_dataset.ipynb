{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d144a1ec-e66d-45b8-baf1-af4641ee23ce",
   "metadata": {},
   "source": [
    "# Bring your own dataset\n",
    "\n",
    "---------\n",
    "*This notebook works best with the conda_python3 kernel on a ml.t3.medium machine*.\n",
    "\n",
    "### This part of our solution design includes \n",
    "\n",
    "- Creating your own `fmbench` compatible dataset from a [HuggingFace dataset](https://huggingface.co/docs/datasets/en/index).\n",
    "\n",
    "- Creating a prompt payload template compatible with your dataset.\n",
    "\n",
    "- Upload the dataset and the prompt payload to Amazon S3 from where it can be used by `fmbench`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eafa135b-2dec-4e2c-9821-bd8268a21492",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if interactive mode is set to no -> pickup fmbench from Python installation path\n",
    "# if interactive mode is set to yes -> pickup fmbench from the current path (one level above this notebook)\n",
    "# if interactive mode is not defined -> pickup fmbench from the current path (one level above this notebook)\n",
    "# the premise is that if run non-interactively then it can only be run through main.py which will set interactive mode to no\n",
    "import os\n",
    "import sys\n",
    "if os.environ.get(\"INTERACTIVE_MODE_SET\", \"yes\") == \"yes\":\n",
    "    sys.path.append(os.path.dirname(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7343d0fb-89cc-48da-8c77-22b8024a7e94",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config file current -> configs/config-llama2-7b-g4dn-g5-trt.yml, None\n",
      "Loaded config: {'general': {'name': 'Llama2-7b-g4dn-g5', 'model_name': 'Llama2-7b'}, 'aws': {'region': 'us-east-1', 'sagemaker_execution_role': 'arn:aws:sts::015469603702:assumed-role/fmbench-role/SageMaker', 'bucket': 'sagemaker-fmbench-write-015469603702'}, 'dir_paths': {'data_prefix': 'data', 'prompts_prefix': 'prompts', 'all_prompts_file': 'all_prompts.csv', 'metrics_dir': 'metrics', 'models_dir': 'models', 'metadata_dir': 'metadata'}, 's3_read_data': {'read_bucket': 'sagemaker-fmbench-read-015469603702', 'scripts_prefix': 'scripts', 'script_files': ['hf_token.txt'], 'source_data_prefix': 'source_data', 'source_data_files': ['2wikimqa_e.jsonl', '2wikimqa.jsonl', 'hotpotqa_e.jsonl', 'hotpotqa.jsonl', 'narrativeqa.jsonl', 'triviaqa_e.jsonl', 'triviaqa.jsonl'], 'tokenizer_prefix': 'tokenizer', 'prompt_template_dir': 'prompt_template', 'prompt_template_file': 'prompt_template_llama2.txt'}, 'run_steps': {'0_setup.ipynb': True, '1_generate_data.ipynb': True, '2_deploy_model.ipynb': True, '3_run_inference.ipynb': True, '4_model_metric_analysis.ipynb': True, '5_cleanup.ipynb': True}, 'datasets': {'prompt_template_keys': ['input', 'context'], 'filters': [{'language': 'en', 'min_length_in_tokens': 1, 'max_length_in_tokens': 500, 'payload_file': 'payload_en_1-500.jsonl'}, {'language': 'en', 'min_length_in_tokens': 500, 'max_length_in_tokens': 1000, 'payload_file': 'payload_en_500-1000.jsonl'}, {'language': 'en', 'min_length_in_tokens': 1000, 'max_length_in_tokens': 2000, 'payload_file': 'payload_en_1000-2000.jsonl'}, {'language': 'en', 'min_length_in_tokens': 2000, 'max_length_in_tokens': 3000, 'payload_file': 'payload_en_2000-3000.jsonl'}, {'language': 'en', 'min_length_in_tokens': 3000, 'max_length_in_tokens': 4000, 'payload_file': 'payload_en_3000-4000.jsonl'}, {'language': 'en', 'min_length_in_tokens': 305, 'max_length_in_tokens': 3997, 'payload_file': 'payload_en_305-3997.jsonl'}]}, 'metrics': {'dataset_of_interest': 'en_2000-3000', 'weights': {'price_per_tx_wt': 0.65, 'latenct_wt': 0.35}}, 'pricing': {'ml.g5.xlarge': 1.006, 'ml.g5.2xlarge': 1.515, 'ml.g5.12xlarge': 7.09, 'ml.g5.24xlarge': 10.18, 'ml.g5.48xlarge': 20.36, 'ml.inf2.24xlarge': 7.79, 'ml.inf2.48xlarge': 15.58, 'ml.p4d.24xlarge': 37.688, 'ml.g4dn.12xlarge': 3.912}, 'inference_parameters': {'do_sample': True, 'temperature': 0.1, 'top_p': 0.92, 'top_k': 120, 'max_new_tokens': 100}, 'experiments': [{'name': 'llama2-7b-g5.xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0', 'model_id': 'meta-textgeneration-llama-2-7b-f', 'model_version': '3.*', 'model_name': 'llama2-7b-f', 'ep_name': 'llama-2-7b-g512xlarge', 'instance_type': 'ml.g5.12xlarge', 'image_uri': '763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.0.1-tgi1.1.0-gpu-py39-cu118-ubuntu20.04', 'deploy': True, 'instance_count': 1, 'deployment_script': 'jumpstart.py', 'inference_script': 'sagemaker_predictor.py', 'payload_files': ['payload_en_1-500.jsonl', 'payload_en_500-1000.jsonl', 'payload_en_1000-2000.jsonl', 'payload_en_2000-3000.jsonl', 'payload_en_3000-4000.jsonl'], 'concurrency_levels': [1, 2, 5, 10], 'accept_eula': True, 'env': {'SAGEMAKER_PROGRAM': 'inference.py', 'ENDPOINT_SERVER_TIMEOUT': '3600', 'MODEL_CACHE_ROOT': '/opt/ml/model', 'SAGEMAKER_ENV': '1', 'HF_MODEL_ID': '/opt/ml/model', 'MAX_INPUT_LENGTH': '4095', 'MAX_TOTAL_TOKENS': '4096', 'SM_NUM_GPUS': '4', 'SAGEMAKER_MODEL_SERVER_WORKERS': '1'}}, {'name': 'Llama2-7b-g4dn-djl-inference-0.26.0-deepspeed0.12.6-cu121', 'model_id': 'meta-llama/Llama-2-7b-hf', 'model_version': '*', 'model_name': 'Llama-2-7b-hf', 'ep_name': 'Llama-2-7b-hf-g4dn', 'download_from_hf_place_in_s3': True, 'model_s3_path': 's3://sagemaker-fmbench-write-015469603702/meta-llama/Llama-2-7b-hf', 'instance_type': 'ml.g4dn.12xlarge', 'image_uri': '763104351884.dkr.ecr.us-east-1.amazonaws.com/djl-inference:0.26.0-deepspeed0.12.6-cu121', 'deploy': True, 'instance_count': 1, 'deployment_script': 'deploy_w_djl_serving.py', 'inference_script': 'sagemaker_predictor.py', 'serving.properties': 'engine=Python\\noption.tensor_parallel_degree=4\\noption.model_id=s3://sagemaker-fmbench-write-015469603702/meta-llama/Llama-2-7b-hf\\noption.max_rolling_batch_size=64\\noption.rolling_batch=vllm\\noption.dtype=fp16\\n', 'payload_files': ['payload_en_1-500.jsonl', 'payload_en_500-1000.jsonl', 'payload_en_1000-2000.jsonl', 'payload_en_2000-3000.jsonl', 'payload_en_3000-4000.jsonl'], 'concurrency_levels': [1, 2, 5, 10], 'accept_eula': True, 'env': None}], 'report': {'per_inference_request_file': 'per_inference_request_results.csv', 'all_metrics_file': 'all_metrics.csv', 'txn_count_for_showing_cost': 10000, 'v_shift_w_single_instance': 0.025, 'v_shift_w_gt_one_instance': 0.025, 'latency_vs_token_len_chart': {'y_ticks': None, 'title': 'Effect of token length on inference latency for \"meta-llama/Llama-2-70b-hf\"'}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomTokenizer, based on HF transformers\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from fmbench.utils import *\n",
    "from fmbench.globals import *\n",
    "from datasets import load_dataset\n",
    "config = load_config(CONFIG_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89998f93-e59a-4d47-9957-ad0b11a089f7",
   "metadata": {},
   "source": [
    "## Convert HuggingFace dataset to jsonl format\n",
    "\n",
    "`fmbench` works with datasets in the [`JSON Lines`](https://jsonlines.org/) format. So here we show how to convert a HuggingFace dataset into JSON lines format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815d021d-ff1c-4275-85ae-128265b0d5fa",
   "metadata": {},
   "source": [
    "Set the `ds_name` to the HuggingFace dataset id, for example [`THUDM/LongBench`](https://huggingface.co/datasets/THUDM/LongBench), [`rajpurkar/squad_v2`](https://huggingface.co/datasets/rajpurkar/squad_v2), [`banking77`](https://huggingface.co/datasets/banking77) or other text datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "657bad51-f5dd-45e0-a08c-cbfd33206301",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_id: str = \"rajpurkar/squad\"\n",
    "ds_name: str = \"plain_text\"\n",
    "ds_split: str = \"train\"\n",
    "# Take a random subset of the dataframe, adjust the value of `N` below as appropriate.\n",
    "# size of random subset of the data\n",
    "ds_N: int = 100\n",
    "\n",
    "# another example\n",
    "# ds_id: str = \"THUDM/LongBench\"\n",
    "# ds_name: str = \"2wikimqa\"\n",
    "# ds_split: str = \"test\"\n",
    "# Take a random subset of the dataframe, adjust the value of `N` below as appropriate.\n",
    "# size of random subset of the data\n",
    "# ds_N: int = 200\n",
    "\n",
    "# another example\n",
    "# ds_id: str = \"banking77\"\n",
    "# ds_name: str = \"default\"\n",
    "# ds_split: str = \"train\"\n",
    "# Take a random subset of the dataframe, adjust the value of `N` below as appropriate.\n",
    "# size of random subset of the data\n",
    "# ds_N: int = 10000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "707c44bd-af91-4268-9d76-35544b0653e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "804665bb6ace4584aa85bd918c4a0795",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/14.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a15161dfa3dc42dabfca80e0a41bedc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.82M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6635d02a9bc4496a7300b2b3c44e784",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/87599 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cc60884acfd46a9aeb4a88b59ef6733",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/10570 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the dataset from huggingface\n",
    "dataset = load_dataset(ds_id, name=ds_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e558518a-c24e-4f6d-becf-3fdbf6c10e78",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 87599\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 10570\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9c55120-b66a-4386-8371-d5544e3d54d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# convert the dataset to a dataframe, for print it out and easy conversion to jsonl\n",
    "df = pd.DataFrame(dataset[ds_split])\n",
    "\n",
    "# some datasets contain a field called column, we would like to call it\n",
    "# input to match it to the prompt template\n",
    "df.rename(columns={\"question\": \"input\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff18dd26-ad8f-449d-bcba-1dd96f00b6ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>input</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5733be284776f41900661182</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>{'text': ['Saint Bernadette Soubirous'], 'answ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5733be284776f4190066117f</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is in front of the Notre Dame Main Building?</td>\n",
       "      <td>{'text': ['a copper statue of Christ'], 'answe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5733be284776f41900661180</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
       "      <td>{'text': ['the Main Building'], 'answer_start'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5733be284776f41900661181</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is the Grotto at Notre Dame?</td>\n",
       "      <td>{'text': ['a Marian place of prayer and reflec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5733be284776f4190066117e</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What sits on top of the Main Building at Notre...</td>\n",
       "      <td>{'text': ['a golden statue of the Virgin Mary'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id                     title  \\\n",
       "0  5733be284776f41900661182  University_of_Notre_Dame   \n",
       "1  5733be284776f4190066117f  University_of_Notre_Dame   \n",
       "2  5733be284776f41900661180  University_of_Notre_Dame   \n",
       "3  5733be284776f41900661181  University_of_Notre_Dame   \n",
       "4  5733be284776f4190066117e  University_of_Notre_Dame   \n",
       "\n",
       "                                             context  \\\n",
       "0  Architecturally, the school has a Catholic cha...   \n",
       "1  Architecturally, the school has a Catholic cha...   \n",
       "2  Architecturally, the school has a Catholic cha...   \n",
       "3  Architecturally, the school has a Catholic cha...   \n",
       "4  Architecturally, the school has a Catholic cha...   \n",
       "\n",
       "                                               input  \\\n",
       "0  To whom did the Virgin Mary allegedly appear i...   \n",
       "1  What is in front of the Notre Dame Main Building?   \n",
       "2  The Basilica of the Sacred heart at Notre Dame...   \n",
       "3                  What is the Grotto at Notre Dame?   \n",
       "4  What sits on top of the Main Building at Notre...   \n",
       "\n",
       "                                             answers  \n",
       "0  {'text': ['Saint Bernadette Soubirous'], 'answ...  \n",
       "1  {'text': ['a copper statue of Christ'], 'answe...  \n",
       "2  {'text': ['the Main Building'], 'answer_start'...  \n",
       "3  {'text': ['a Marian place of prayer and reflec...  \n",
       "4  {'text': ['a golden statue of the Virgin Mary'...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703cc0f9-a86b-42de-81b4-21a6a3048fe7",
   "metadata": {},
   "source": [
    "Subset the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30c4e481-2cd4-4341-b910-c5172eafe400",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset shape before random subset = (100, 5)\n",
      "dataset shape before random subset = (100, 5)\n"
     ]
    }
   ],
   "source": [
    "print(f\"dataset shape before random subset = {df.shape}\")\n",
    "df = df.sample(n=ds_N)\n",
    "print(f\"dataset shape before random subset = {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7fcadf-0ca7-4123-92d6-ed7b188cfd4b",
   "metadata": {},
   "source": [
    "Convert to json lines format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adb38f44-9788-4d26-b77e-2dde3feddfb0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\":\"5727fcf24b864d190016416a\",\"title\":\"Time\",\"context\":\"The hourglass uses the flow of sand to measure the flow of time. They were used in navigation. Ferdinand Magellan used 18 glasses on each ship for his circumnavigation of the globe (1522). Incense sticks and candles were, and are, commonly used to measure time in temples and churches across the globe. Waterclocks, and later, mechanical clocks, were used to mark the events of the abbeys and monasteries of the Middle Ages. Richard of Wallingford (1292\\u20131336), abbot of St. Alban's abbey, famously built a mechanical clock as an astronomical orrery about 1330. Great advances in accurate time-keeping were made by Galileo Galilei and especially Christiaan Huygens with the invention of pendulum driven clocks along with the invention of the minute hand by Jost Burgi.\",\"input\":\"Which device uses the flow of sand to measure time?\",\"answers\":{\"text\":[\"The hourglass\"],\"answer_start\":[0]}}\n",
      "{\"id\":\"572ff545a23a5019007fcbb3\",\"title\":\"Antenn\n"
     ]
    }
   ],
   "source": [
    "jsonl_content = df.to_json(orient='records', lines=True)\n",
    "print(jsonl_content[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461c64b4-d0c8-41d5-80a2-86581d176a20",
   "metadata": {},
   "source": [
    "## Upload the dataset to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0bfecbb1-6355-4f52-86a4-53579d867629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-fmbench-read-015469603702/source_data/rajpurkar/squad.jsonl'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket: str = config['s3_read_data']['read_bucket']\n",
    "prefix: str = config['s3_read_data']['source_data_prefix']\n",
    "file_name: str = f\"{ds_id}.jsonl\"\n",
    "write_to_s3(jsonl_content, bucket, prefix, \"\", file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c6fd45-fc80-45f3-a184-9cad6a1cd706",
   "metadata": {},
   "source": [
    "## Create a prompt template and upload it to S3\n",
    "The prompt template is specific to the model under test and also the dataset being used. The variables used in the template, such as `context` and `input` must exist in the dataset being used so that this prompt template can be converted into an actual prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce19f066-10d0-4430-aff8-fb9120b315f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template for BERT\n",
    "bucket: str = config['s3_read_data']['read_bucket']\n",
    "prefix: str = config['s3_read_data']['prompt_template_dir']\n",
    "file_name: str = config['s3_read_data']['prompt_template_file']\n",
    "content: str = \"\"\"<s>[INST] <<SYS>>\n",
    "You are an assistant for question-answering tasks. Use the following pieces of retrieved context in the section demarcated by \"```\" to answer the question. If you don't know the answer just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "<</SYS>>\n",
    "\n",
    "```\n",
    "{context}\n",
    "```\n",
    "\n",
    "Question: {input}\n",
    "\n",
    "[/INST]\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "write_to_s3(content, bucket, prefix, \"\", file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef34360-c855-49e6-a624-0209ba09939f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_my_python311",
   "language": "python",
   "name": "conda_my_python311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
